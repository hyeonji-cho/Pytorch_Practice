{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN으로 손글씨 숫자 이미지 분류하기\n",
        "\n",
        ">### 1. 모듈 및 분석 환경 설정\n",
        "\n",
        ">### 2. 데이터 불러오기\n",
        "\n",
        ">### 3. 모델 학습\n",
        "\n",
        ">### 4. 모델 평가"
      ],
      "metadata": {
        "id": "OvraejPXcN5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.모듈 및 분석 환경 설정\n",
        "\n"
      ],
      "metadata": {
        "id": "NKgtKFXoc_24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 모듈 불러오기"
      ],
      "metadata": {
        "id": "mxF4EbAzdPv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elrBNiQVRfPq",
        "outputId": "64639f7b-1c54-4545-e9de-ca3490ea887a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "RlhgEC6bdO3O"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 분석 환경 설정"
      ],
      "metadata": {
        "id": "LMgc_xkrd0Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')\n",
        "\n",
        "print('Current cuda device is', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px-mk1M0cXZc",
        "outputId": "02e900eb-0162-44fa-dfd1-2a807988e27d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current cuda device is cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* HyperParameter 지정"
      ],
      "metadata": {
        "id": "C7u0kt23eSMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "epoch_num = 15\n",
        "learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "Vm6fzbeFeVxb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터 불러오기"
      ],
      "metadata": {
        "id": "-qZgFSMHepWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root = './data', train = True, download = True, transform = transforms.ToTensor())  # transform : MNIST 데이터를 저장과 동시에 전처리\n",
        "test_data = datasets.MNIST(root = './data', train = False, download = True, transform = transforms.ToTensor())\n",
        "\n",
        "print('number of training data: ', len(train_data))\n",
        "print('number of test data: ', len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhyKQScIes4l",
        "outputId": "01053427-f20d-47d1-94ca-2928587eebcf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training data:  60000\n",
            "number of test data:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* MNIST 데이터 확인하기"
      ],
      "metadata": {
        "id": "V7ejPXZ-f3Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]  # 첫번째 학습데이터의 입력 데이터와 정답 저장\n",
        "\n",
        "plt.imshow(image.squeeze().numpy(), cmap = 'gray')  # [1,28,28] 3차원 -> [28,28] 2차원\n",
        "plt.title('label : %s' %label)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "tZE-ydz_fx7D",
        "outputId": "5a41b2fa-eb23-4e55-a2f8-5e1d8cb55717"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 미니 배치 구성하기"
      ],
      "metadata": {
        "id": "_h5fZLokgpzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)  # 학습 과정을 반복 시행할 때마다 미니 배치를 하나씩 불러옴\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "first_batch = train_loader.__iter__().__next__()\n",
        "print('{:15s} | {:<25s} | {}'.format('name', 'type', 'size'))\n",
        "print('{:15s} | {:<25s} | {}'.format('Num of Batch', '', len(train_loader)))  # 60000 / 50 = 1200 미니배치\n",
        "print('{:15s} | {:<25s} | {}'.format('first_batch', str(type(first_batch)), len(first_batch)))\n",
        "print('{:15s} | {:<25s} | {}'.format('first_batch[0]', str(type(first_batch[0])), first_batch[0].shape))  # [Batch Size, Channel, Width, Height]\n",
        "print('{:15s} | {:<25s} | {}'.format('first_batch[1]', str(type(first_batch[1])), first_batch[1].shape))  # 미니 배치의 정답 50개"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wDmDVM4gv8M",
        "outputId": "0368e118-20b9-4e3b-c3ed-50c8fe2efe0a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name            | type                      | size\n",
            "Num of Batch    |                           | 1200\n",
            "first_batch     | <class 'list'>            | 2\n",
            "first_batch[0]  | <class 'torch.Tensor'>    | torch.Size([50, 1, 28, 28])\n",
            "first_batch[1]  | <class 'torch.Tensor'>    | torch.Size([50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 한 개는 3차원이지만 데이터가 여러 개 쌓여 차원이 하나 더 늘어 4차원 Tensor가 된다."
      ],
      "metadata": {
        "id": "ihJiqdGXkAbG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 모델 학습"
      ],
      "metadata": {
        "id": "az-IMbcbkL7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1UGkfy6sUh_net-6_GPDhHoRpKXYEDXII' width=\"400\" /><br>\n",
        "</center>"
      ],
      "metadata": {
        "id": "esqGi9k6oeRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):  # CNN 클래스 정의\n",
        "    def __init__(self):  # 모델에서 사용되는 가중치 정의\n",
        "        super(CNN, self).__init__()  # nn.Module 클래스의 속성을 상속받고 초기화\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)  # 입력채널, 출력채널, 커널, 스트라이드\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)  # conv1 출력채널 = conv2 입력채널\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)  # 9216크기의 벡터 -> 128크기의 벡터\n",
        "        self.fc2 = nn.Linear(128, 10)  # 128크기의 벡터 -> 10크기의 벡터\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)  # conv1 레이어 통과\n",
        "        x = F.relu(x)  # ReLU 활성 함수 적용\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)  # 고차원의 Tensor를 1차원 벡터로 변환\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "Vt3noUpQkPIt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Optimizer 및 손실 함수 정의"
      ],
      "metadata": {
        "id": "43qF7DDiMrph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류 문제 -> 교차 엔트로피 사용"
      ],
      "metadata": {
        "id": "SoZVIAYMMuc_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 설계한 CNN 모형 확인하기"
      ],
      "metadata": {
        "id": "yRS4lpI_NNK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki0jSLFzQfvF",
        "outputId": "e4658fb0-6058-4942-89e3-c37c28aea3f0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 모델 학습"
      ],
      "metadata": {
        "id": "oSY6_ZsvR7WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()  # 학습 모드로 실행\n",
        "i = 0\n",
        "for epoch in range(epoch_num):\n",
        "    for data, target in train_loader:\n",
        "        data = data.to(device)  # 미니 배치의 데이터를 device에 할당\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()  # 학습 시작 전, optimizer의 gradient 초기화\n",
        "        output = model(data)  # FeedForward 연산으로 결괏값 계산\n",
        "        loss = criterion(output, target)  # 손실 함수 계산\n",
        "        loss.backward()  # 손실 함수를 통해 Gradient 계산\n",
        "        optimizer.step()  # Gradient 통해 모델의 가중치 업데이트\n",
        "        if i % 1000 == 0:\n",
        "            print('Train Step: {}\\tLoss: {:.3f}'.format(i, loss.item()))  # 손실함수 출력\n",
        "        i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-QoUKCpR85P",
        "outputId": "2948a1db-dc41-4a43-bd62-e6763a1d24df"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1345: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Step: 0\tLoss: 2.308\n",
            "Train Step: 1000\tLoss: 0.145\n",
            "Train Step: 2000\tLoss: 0.178\n",
            "Train Step: 3000\tLoss: 0.195\n",
            "Train Step: 4000\tLoss: 0.035\n",
            "Train Step: 5000\tLoss: 0.176\n",
            "Train Step: 6000\tLoss: 0.050\n",
            "Train Step: 7000\tLoss: 0.070\n",
            "Train Step: 8000\tLoss: 0.054\n",
            "Train Step: 9000\tLoss: 0.107\n",
            "Train Step: 10000\tLoss: 0.023\n",
            "Train Step: 11000\tLoss: 0.040\n",
            "Train Step: 12000\tLoss: 0.055\n",
            "Train Step: 13000\tLoss: 0.026\n",
            "Train Step: 14000\tLoss: 0.038\n",
            "Train Step: 15000\tLoss: 0.031\n",
            "Train Step: 16000\tLoss: 0.038\n",
            "Train Step: 17000\tLoss: 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 모델 평가"
      ],
      "metadata": {
        "id": "vuD8jkAnTJxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # 평가 모드 실행\n",
        "correct = 0\n",
        "for data, target in test_loader:\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    output = model(data)  # 미니 배치 데이터를 모델에 통과시켜 결괏값 계산\n",
        "    prediction = output.data.max(1)[1]  # Log-Softmax 값이 가장 큰 인덱스를 예측값으로 저장\n",
        "    correct += prediction.eq(target.data).sum()\n",
        "\n",
        "print('Test set: Accuracy: {:.2f}%'.format(100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_caB6OfaTMRD",
        "outputId": "bd8f8e22-26b8-4388-ef46-145387b5b620"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1345: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Accuracy: 98.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "output.data.max(1)[1]\n",
        "\n",
        "\n",
        "output: 모델의 출력으로, 모델이 각 클래스에 대해 계산한 로그 확률값(Log probabilities)을 포함하는 Tensor입니다. 크기는 (배치 크기, 클래스 수)입니다.\n",
        "\n",
        ".data: PyTorch에서 Tensor의 값을 직접 접근하기 위한 속성입니다. 이를 통해 Tensor의 값을 조작하고 검사할 수 있습니다. (단, .data를 사용할 때는 기울기 정보가 무시됩니다.)\n",
        "\n",
        ".max(1): 각 행(row)에서 최댓값을 반환하는 함수입니다. 이 경우에는 각 데이터 샘플에 대해 최댓값과 해당 최댓값의 인덱스를 반환합니다. 반환값은 튜플 형태로 (최댓값, 최댓값의 인덱스)입니다.\n",
        "\n",
        "[1]: 튜플의 두 번째 요소를 선택합니다. 여기서는 최댓값의 인덱스에 해당하는 부분입니다. 따라서 최종적으로 반환되는 값은 각 데이터 샘플에 대한 예측된 클래스의 인덱스를 나타내는 Tensor입니다."
      ],
      "metadata": {
        "id": "hJjreCDoUEU2"
      }
    }
  ]
}